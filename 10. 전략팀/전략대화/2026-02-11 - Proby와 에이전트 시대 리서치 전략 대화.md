## 대화 개요

- **날짜**: 2026-02-11  
- **참여자**: Founder ↔ AI 전략 에이전트  
- **주제**: OpenClaw 인사이트를 기반으로, 에이전트 시대에 UserTesting/SurveyMonkey, 리서치 에이전시, Vertical AI, Proby의 Moat가 어떻게 재정의되는지에 대한 전략 대화 정리.

---

## 1. 왜 UserTesting, SurveyMonkey 같은 툴은 사라진다고 보는가?

### 1-1. OpenClaw 인사이트 요약

- **로컬 실행 에이전트의 부상**  
  - OpenClaw는 클라우드가 아닌 **사용자 컴퓨터 로컬에서 실행**되며, 모든 기기·파일·서비스에 접근해 자동으로 일을 처리한다.

- **창발적 워크플로우**  
  - 개발자가 직접 짜지 않은 워크플로우(음성 파일 포맷 감지 → ffmpeg 변환 → OpenAI로 전사 등)를 모델이 스스로 구성해 9초 만에 해결하는 사례가 등장.

- **“데이터 관리형 앱”의 대량 소멸**  
  - MyFitnessPal, 할 일 앱처럼 **데이터를 입력·저장·조회·알림하는 앱**들은  
    에이전트가 자연스럽게 더 잘 처리할 수 있어서 **80% 정도는 사라질 것**이라는 전망.

- **Bot-to-Bot·Bot-to-Human 경제**  
  - 사용자의 봇이 레스토랑 봇과 협상하거나,  
  - 봇이 인간을 고용해서 오프라인 태스크(줄 서기, 전화, 방문 등)를 처리하는 패턴이 자연스럽게 등장.

### 1-2. 이 관점에서 본 UserTesting/SurveyMonkey

- UserTesting/SurveyMonkey는 근본적으로 **“설문/테스트를 세팅하고, 응답 데이터를 저장·필터·시각화하는 UI 레이어”**다.
- OpenClaw 세계관에서는:
  - 에이전트가 **참가자를 찾고, 인터뷰/설문을 세팅하고, 대화를 진행하고, 응답을 정리·요약·인사이트까지 도출**할 수 있다.
  - 사용자는 “브랜딩에 대한 유저 반응 10명만 빨리 확인해줘”라고 말하면, 에이전트가 **툴/폼/대시보드를 의식할 필요 없이 모든 단계를 처리**한다.
- 따라서 **“폼을 만들고, 링크를 뿌리고, 응답을 모으는 SaaS”**는  
  에이전트의 자연스러운 대화형 UX에 흡수될 위험이 크다.

---

## 2. 리서치 에이전시에게도 같은 논리가 적용되는가?

### 2-1. 플랫폼 vs. 에이전시

질문:  
> 이 인사이트는 UserTesting/SurveyMonkey 같은 “플랫폼 인하우스”에게만 해당되는 관점 아닌가?  
> 의뢰를 받아서 리서치를 하는 Research Agency에는 덜 적용되는 것 아닐까?

정리:

- **툴 오퍼레이터형 에이전시에는 같은 압력이 걸린다.**  
  - 단순히 “설문 세팅, 링크 발송, UT 진행, 녹화/노트 정리” 같은 **툴 조작과 기본 분석**으로 먹고사는 에이전시는  
    에이전트가 같은 일을 더 싸고 빠르게, 24/7로 수행할 수 있어 위협을 받는다.

- **반대로, 인간이 남는 레이어는 “조직/정치/책임”에 가깝다.**  
  - 문제 정의, 세그먼트 설계, 조직의 힘 관계를 고려한 의사결정·스토리텔링,  
  - 리서치 결과를 실제 의사결정과 변화로 연결하는 일은 **회사 정치와 책임 구조의 일부**다.
  - 이 영역은 단순 자동화가 아니라, **누가 책임을 지고, 누구를 설득하며, 어떤 타이밍/형식으로 던지는지**가 중요하다.

따라서:

- “리서치를 대신해주는 손과 눈”으로서의 에이전시는 에이전트에 의해 상당 부분 대체 위험.
- “조직 정치와 책임을 함께 짊어지며, 변화를 설계하는 파트너”로 올라간 에이전시는  
  에이전트를 강력한 무기로 쓰면서도 **여전히 남는 역할**이 있다.

---

## 3. “결국 그 레이어도 AI가 더 잘하지 않냐?”에 대한 논의

질문:  
> “고객사와 함께 문제 정의·해석·조직 변화까지 책임지는 AI-native 리서치 파트너로 올라가야 한다”  
> 이것조차도 그냥 AI가 하게 될 것 같고, 더 잘할 것 같은데?

정리:

- **인지 능력 관점에서 보면, 맞는 말이다.**  
  - 문제 정의, 인사이트 도출, 옵션 생성은 모델이 이미 잘하고, 더 잘하게 될 것이다.

- **하지만 “책임·권한·정치” 레이어는 느리게 움직인다.**
  - 누가 최종 서명을 하는지, 실패했을 때 누구 목이 날아가는지,  
    이사회·규제기관·노조·언론 등 외부 이해관계자가 “AI의 결정”을 어떻게 받아들이는지 등은  
    **법·제도·조직 문화의 문제**다.
  - 일정 기간 동안은 “AI가 제안 → 인간이 최종 책임자로 승인·발표”라는 구조를 유지하려는 힘이 강하다.

- **설득·동원·감정의 레이어**  
  - 전략이 논리적으로 옳은지와 별개로,  
    “어떤 언어와 형식으로 누구에게 전달해야 실제로 움직이는가?”는 감정·관계·역사 맥락에 따른다.

따라서 현실적인 미래상은:

- **AI가 인지 노동(문제 정의·해석·전략 옵션 생성)의 80%를 담당하고,**  
- **인간(에이전시/리더)이 조직/정치/책임 노동을 담당하면서 둘이 붙어 움직이는 Bot-to-Human 하이브리드 구조**에 가깝다.

---

## 4. “SurveyMonkey Bot에게 의뢰하는 구조”에 대한 해석

질문:  
> “제 생각엔 SurveyMonkey Bot에게 의뢰하는 형태가 될 것 같다”  
> 이 평가에 대해서 어떻게 생각하는가?

정리:

- **방향성은 타당하다.**
  - “인간이 설문 툴 대시보드에 로그인하는 세계 →  
     인간의 메인 에이전트가 `SurveyMonkey Bot` 같은 전문 리서치 봇에게 일을 주는 세계”로 이동할 수 있다.
  - 이는 OpenClaw가 말하는 Bot-to-Bot 경제와 잘 부합한다.

- **그러나 “굳이 SurveyMonkey일 필요가 있냐”의 문제가 남는다.**
  - 단순 “폼 생성/응답 수집/기본 분석 봇”은 금방 범용화된다.
  - 살아남으려면:
    - 대규모·고품질 패널 네트워크  
    - 장기간 축적된 트래킹 데이터  
    - 강한 컴플라이언스 인프라  
    - 특정 산업·국가에 특화된 도메인 지식과 접근권  
    같은, **에이전트가 혼자선 쉽게 만들 수 없는 리서치 인프라/자산**을 가져야 한다.

즉:

- “SurveyMonkey Bot에게 의뢰”하는 미래는 있을 수 있지만,  
- 그때 중요한 건 **브랜드명이 아니라, 그 봇이 가진 패널·데이터·규제 인프라·신뢰 자산**이다.

---

## 5. Vertical AI Agent(예: AI Lawyer, AI Personal Trainer)의 운명

질문:  
> 특별한 데이터/자산/규제 문제 없이, 한 업무를 잘하기 위해 사고력을 높인 Vertical AI Agent들(AI Lawyer, AI PT 등)은 결국 사라질까?

정리:

- **사고력만 높은 Vertical의 상당수는 “큰 에이전트 안의 기능/모드”로 흡수될 가능성이 크다.**
  - 유저는 수십 개의 Vertical 앱을 쓰기보다는,  
    **“내 메인 에이전트에게 ‘법률 모드’, ‘운동 모드’로 자연어로 부탁하는 경험”**을 선호한다.
  - 기술적으로도, 시간이 갈수록 범용 모델 + 약간의 설정/코드로 vertical 기능들을 재현하기 쉬워진다.

- **그러나 “사고력 + X(현실 세계 자산/책임)”를 가진 Vertical은 남는다.**
  - 예: 실제 변호사/법무법인 라이선스와 보험 위에 올라간 AI Lawyer  
  - 예: 병원/보험/피트니스 센터 등 헬스케어 인프라와 통합된 AI PT
  - 이런 Vertical은 **책임·규제·오프라인 네트워크·데이터 등 현실 자산과 결합**되어 있어, 단순 스킬로 완전히 평준화되기 어렵다.

---

## 6. “에이전트가 혼자선 만들기 어려운 것”의 구체적 예시

- **대규모·고품질 패널 네트워크**
  - 특정 산업/직군/국가의 응답자 풀, 리텐션·신뢰 히스토리가 관리된 집합.
- **독점성 있는 장기 데이터 자산**
  - 5~10년 이상 쌓인 행동 데이터, brand lift, 전환/리텐션 기록 등.
- **규제·컴플라이언스·법적 인프라**
  - GDPR, HIPAA, 국내 개인정보보호법 준수 체계, 각종 인증과 감사 이력.
- **오프라인/현장 리크루팅 및 운영 인프라**
  - FGI, 샵얼롱, 현장 인터뷰/관찰을 위한 실제 사람·공간·장비·프로세스.
- **브랜드·신뢰·레퍼런스**
  - “이 회사가 조사한 결과는 경영진이 진지하게 듣는다” 수준의 브랜드 파워.
- **조직 변화·정치 조율 능력**
  - 내부 의사결정 구조와 이해관계를 이해하고, 실제로 변화를 관철시킬 수 있는 힘.

이 모든 것은 **시간·사람·제도·현실 세계가 축적된 자산**이라,  
에이전트가 “혼자” 코드와 텍스트만으로 즉시 생성하기는 어렵다.

---

## 7. Proby의 Moat 방향에 대한 논의

아이디어:

1. **Proby를 통해 극도로 왕성하게 고객 보이스를 수집하고,**
2. **그것을 회사별 로컬 Repository로 구조화/저장한 뒤,**
3. **Cursor 같은 로컬 에이전트가 이 Repository를 상시 참조하게 만들고,**
4. **PM/PD/디자이너/임원 등 이해관계자가 필요한 순간에, 자신의 목적 달성을 위해 유저 보이스를 바로 꺼내 쓰게 한다.**

질문:  
> 이 구조는 Moat를 강하게 만드는 방향이라고 볼 수 있는가?

정리:

- **강한 Moat 방향이 맞다.**
  - Proby를 통해 쌓인 **고품질 도메인 특화 유저 발화 데이터**가  
    회사별로 로컬에 축적되면, 이는 **대체하기 어려운 리서치 데이터 레이크**가 된다.
  - Cursor와 같은 로컬 에이전트가 이 Repository를 상시 참조하면,  
    조직은 **기밀성을 유지하면서도 언제든 실제 사용자 목소리를 불러와 의사결정에 활용**할 수 있다.
  - 이 구조가 회사의 회의·기획·리뷰 워크플로우에 깊게 박히면,  
    Proby는 “리서치 도구”가 아니라 **“의사결정 OS의 일부”**로 자리 잡게 되고, 교체 비용이 매우 커진다.

요약:

- 단순히 “유저 인터뷰를 잘하는 AI”가 아니라,  
- **유저 보이스를 장기간·고빈도로 축적하고, 로컬 에이전트와 결합해 언제든 꺼내 쓸 수 있게 만드는 인프라**가  
  Proby의 핵심 Moat가 될 수 있다.

---

## 8. 조직 정치 레버리지의 예시

- **외부 권위를 빌리는 경우**
  - 내부 팀이 말하면 무시되던 주장도, 유명 컨설팅/리서치사의 리포트로 포장되면 이사회 안건이 된다.

- **리서치를 무기로 예산·조직 개편을 따내는 경우**
  - 특정 본부가 자신의 아젠다(새로운 팀, 기능, 예산)를 밀어붙이기 위해  
    유리한 유저 인사이트/데이터를 “시장·사용자가 이렇게 말한다”는 형태로 제시.

- **스폰서에 따라 같은 결과의 운명이 달라지는 경우**
  - 같은 리포트라도 CEO/CPO/BU장이 스폰서면 바로 실행,  
    중간관리자만 들고 있으면 우선순위 뒤로 밀리는 사례.

- **기득권을 깨는 인사이트를 외부 입으로 말하게 하는 경우**
  - 조직 내부에서 말하면 공격받을 내용도,  
    외부 에이전시/플랫폼 리포트로 제시하면 “어쩔 수 없이 받아들여야 하는 외부 시그널”로 포지셔닝된다.

- **타이밍과 포맷 설계**
  - 분기 전략 워크숍 전/후, 어떤 포맷(1p 요약, 대시보드, 유저 클립 모음)으로 던지느냐에 따라  
    설득력과 압박감이 달라진다.

Proby/에이전트가 장기적으로 노려야 할 것은,  
